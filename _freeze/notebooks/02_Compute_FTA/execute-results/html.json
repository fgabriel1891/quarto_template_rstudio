{
  "hash": "d46ce65f5655165ca01902e14ba5c423",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Calculating Functional Trophic Asymmetry\"\nformat: \n  html:\n    theme: \"flatly\" # A clean, flat theme suitable for scientific documents\n    toc: true # Enables table of contents\n    toc-depth: 3 # Adjusts depth of table of contents; change as needed\n    number-sections: true # Enables section numbering\n    fig-width: 6 # Sets default figure width to 6 inches\n    fig-height: 4 # Sets default figure height to 4 inches\n    fig-align: \"center\" # Centers figures\neditor: visual\nexecute:\n  eval: false\n  echo: true\n---\n\n\n\n# Compute observed values of FTA and H2\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# A function to calculate metrics for a grid\ncalc_net_metric <- function(grid_test, SBMs){\n  \n  \n  #grid_test <- all_assemblages_prunned %>% split(.$grid) %>% pluck(1)\n  \n  a <- grid_test %>% \n    distinct(id, taxa, SBM_G) %>% \n    split(.$taxa)\n  \n  \n  fr_palm <- table(a[[1]]$SBM_G)\n  \n  fr_mammals <- table(a[[2]]$SBM_G)\n  \n  ## compute normalized asymmetry \n  \n  fr_norm_palm <- fr_palm/sum(fr_palm)\n  \n  fr_norm_mammals <- fr_mammals/sum(fr_mammals)\n  \n  fta <- abs(fr_norm_palm - fr_norm_mammals)\n  \n  ## compute specialization\n  n <- expand.grid(pluck(a,'mammals', 'id'), pluck(a,'palm', 'id')) \n  \n  \n  areas <- grid_test %>% \n    split(.$taxa) %>% \n    map(~{\n      .x %>% \n        mutate(area = as.numeric(area)) %>% \n        group_by(id) %>% \n        summarize(area_sum = sum(area))\n      \n    }) %>% \n    bind_rows() \n  \n  n <- n %>% \n    left_join(pluck(a,'mammals'), by = c('Var1' = 'id')) %>% \n    left_join(pluck(a,'palm'), by = c('Var2' = 'id')) %>% \n    left_join(areas, by = c('Var1' = 'id') ) %>% \n    left_join(areas, by = c('Var2' = 'id') )\n  \n  n$intPro <- sapply(1:length(n$Var1), function(i) \n    (SBMs$SBM1$Omega_rs[n$SBM_G.x[i], n$SBM_G.y[i]]))\n  \n  n <- n %>% \n    mutate(int_area = ((area_sum.x ) / sum(area_sum.x,area_sum.y)) * ((area_sum.y ) / sum(area_sum.x,area_sum.y)))\n  \n  n$n_geog_dist <- st_distance(x = n$geometry.x,y = n$geometry.y) %>% \n    diag()\n  \n  n$int_final <- scales::rescale(n$int_area,c(0,1)) * (scales::rescale(n$int_area,c(0,1)) * scales::rescale(as.numeric(n$n_geog_dist),c(0,1)))\n  \n  netT <- xtabs(int_final~Var1 + Var2, n)\n  \n  h2 <-  cassandRa::RarefyNetwork(netT,\n                                  abs_sample_levels = 100,\n                                  metrics = c(\"H2\"))\n  \n  \n  h2 <- h2$H2 |> median()\n  \n  \n  return(list(fr_palm = fr_palm, \n              fr_mammals = fr_mammals, \n              fr_norm_palm = fr_norm_palm, \n              fr_norm_mammals = fr_norm_mammals, \n              fta = fta, \n              netT = netT, \n              h2 = h2))\n}    \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncal_net_metric_safe <- safely(calc_net_metric)\n\n# # unit test \nsystem.time({\n  \n  test_res <-  cal_net_metric_safe(all_assemblages_prunned %>% split(.$grid) %>% pluck(1), SBMs)\n})\n\ntest_res$result\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nall_assemblages_prunned2 <- all_assemblages_prunned\n\nall_assemblages_prunned2$geometry <- NULL\n\nall_assemblages_prunned2 |> \n  group_by(SBM_G)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nall_assemblages_prunned$grid %>% unique() %>% length()\n\nlibrary(furrr)\nplan(multisession, workers = 10)\n\n\nmy_net__output <- \n  all_assemblages_prunned %>% split(.$grid) %>% \n  furrr::future_map(function(grid) {\n    cal_net_metric_safe(grid, SBMs)\n  }) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsaveRDS(my_net__output, '00_Data/02_species_interactions/final-networks-grid.RDS')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmy_networks <- readRDS('00_Data/02_species_interactions/final-networks-grid.RDS')\n\n## Extract results \n\nfta_obs <- \n  my_networks |> \n  map(~.x$result) |>\n  map(~.x$fta |> unlist()) |>\n  bind_rows() |>\n  mutate('grid' = names(my_networks))\n\nfr_palms <- \n  my_networks |> \n  map(~.x$result) |>\n  map(~.x$fr_palm |> unlist()) |>\n  bind_rows() |>\n  mutate('grid' = names(my_networks))\n\n\nfr_mammals <- \n  my_networks |> \n  map(~.x$result) |>\n  map(~.x$fr_mammals |> unlist()) |>\n  bind_rows() |>\n  mutate('grid' = names(my_networks))\n\nfr_norm_palms <- \n  my_networks |> \n  map(~.x$result) |>\n  map(~.x$fr_norm_palm |> unlist()) |>\n  bind_rows() |>\n  mutate('grid' = names(my_networks))\n\n\n\n\n\nfr_norm_mammals <- \n  my_networks |> \n  map(~.x$result) |>\n  map(~.x$fr_norm_mammals |> unlist()) |>\n  bind_rows() |>\n  mutate('grid' = names(my_networks))\n\nh2_grid <- \n  my_networks |> \n  map(~.x$result) |>\n  map(~.x$h2 |> unlist()) |>\n  unlist() |>\n  data.frame() |> \n  setNames('h2') |>\n  rownames_to_column('grid')\n```\n:::\n\n\n# Computing FTA z-score resampling within each biogeographic region\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# A function to calculate metrics for a grid (for zcores)\ncalc_net_metric2 <- function(grid_test, SBMs){\n  \n  \n  #grid_test <- expected_comm\n  \n  a <- grid_test %>% \n    distinct(id, taxa, SBM_G) %>% \n    split(.$taxa)\n  \n  \n  fr_palm <- table(a[[1]]$SBM_G)\n  \n  fr_mammals <- table(a[[2]]$SBM_G)\n  \n  ## compute normalized asymmetry \n  \n  fr_norm_palm <- fr_palm/sum(fr_palm)\n  \n  fr_norm_mammals <- fr_mammals/sum(fr_mammals)\n  \n  fta <- abs(fr_norm_palm - fr_norm_mammals)\n  \n  ## compute specialization\n  n <- expand.grid(pluck(a,'mammals', 'id'), pluck(a,'palm', 'id')) \n  \n  \n  \n  n <- n %>% \n    left_join(pluck(a,'mammals'), by = c('Var1' = 'id')) %>% \n    left_join(pluck(a,'palm'), by = c('Var2' = 'id')) \n  \n  n$intPro <- sapply(1:length(n$Var1), function(i) \n    (SBMs$SBM1$Omega_rs[n$SBM_G.x[i], n$SBM_G.y[i]]))\n  \n  netT <- xtabs(intPro~Var1 + Var2, n)\n  \n  h2 <-  cassandRa::RarefyNetwork(netT,\n                                  abs_sample_levels = 100,\n                                  metrics = c(\"H2\"))\n  \n  \n  h2 <- h2$H2 |> median()\n  \n  \n  return(list(fr_palm = fr_palm, \n              fr_mammals = fr_mammals, \n              fr_norm_palm = fr_norm_palm, \n              fr_norm_mammals = fr_norm_mammals, \n              fta = fta, \n              netT = netT, \n              h2 = h2))\n}    \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nall_assemblages_prunned |> head()\n\n## add biogeographic region based on xy \n\nxy_sf <- st_as_sf(all_assemblages_prunned, coords = c(\"cord_x\", \"cord_y\"), crs = st_crs(neotropics))\n\n## make sure crs match \n\nxy_sf <- st_set_crs(xy_sf, st_crs(neotropics))\n\n\nall_assemblages_prunned_biog <- st_join(xy_sf, neotropics)\n\nall_assemblages_prunned_biog <- \n  all_assemblages_prunned_biog |> \n  group_by(id, taxa, grid, Dominions) |> \n  slice(1)\n\nhead(all_assemblages_prunned_biog)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nall_assemblages_prunned_biog2 <-all_assemblages_prunned_biog\n\nall_assemblages_prunned_biog2$geometry <- NULL\n\nsp_per_sbm <- all_assemblages_prunned_biog2 |>\n  group_by(Dominions, SBM_G, taxa) |>\n  summarise(n = n_distinct(id)) |>\n  filter(!is.na(taxa), !is.na(SBM_G), !is.na(Dominions)) |>\n  ggplot() + \n  # make a stacked barplot\n  geom_bar(aes(x = SBM_G, y = n, fill = taxa), stat = \"identity\") +\n  theme_minimal() + \n  facet_wrap(~Dominions, scales = 'free_y') +\n  # color darkgreen palm and firebrick mammal \n  scale_fill_manual(values = c('firebrick2', 'darkgreen')) \n\n\nall_assemblages_prunned_biog2 |>\n  filter(SBM_G == 5) |>\n  pull(id) |>\n  unique()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ngrids_to_sample <- all_assemblages_prunned$grid |> unique() \n\n\n\n\n# Define function to compute expected values \n\nget_expected_val <- function(all_assemblages_prunned_biog, grid_to_sample, SBMs){\n  \n  biog_to_sample <- (all_assemblages_prunned_biog$Dominions[all_assemblages_prunned_biog$grid == grid_to_sample ] |> \n                       table() |> sort(decreasing = T))[1] |> names()\n  \n  expected_comm <- \n    all_assemblages_prunned_biog |>\n    filter(Dominions %in% biog_to_sample) %>% \n    split(.$taxa) |>\n    map(~ .x %>% \n          group_by(id) |> \n          slice(1) |> \n          ungroup() |>\n          slice_sample(n = 10)) |>\n    bind_rows()\n  \n  \n  \n  return(calc_net_metric2(expected_comm, SBMs))\n  \n  \n}\n\n\n\n## Make safe version of the function\n\nsafe_expected_values <- function(n_rep, all_assemblages_prunned_biog, grids_to_sample, SBMs){\n  \n  replicate(n_rep,get_expected_val(all_assemblages_prunned_biog, grids_to_sample, SBMs))\n  \n}\n\nsafe_expected_values <- safely(safe_expected_values)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncl <- NULL\n## open a parallel cluster to run safe_expected_values in parallel \n\nlibrary(parallel)\nlibrary(foreach)\nlibrary(doParallel)\n\n# Register parallel backend\ncl <- makeCluster(10)\nregisterDoParallel(cl)\n\n## Export variables and libraries to each cluster\nclusterExport(cl, c('all_assemblages_prunned_biog', 'grids_to_sample', 'SBMs', 'calc_net_metric2', 'get_expected_val','safe_expected_values'))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(sf)\n  library(cassandRa)\n  library(vegan)\n})\n\n# parallel::stopCluster(cl)\n\n# parallel::stopCluster(cl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Sample 100 grids and apply the function in parallel using foreach\n\ngsample <- (grids_to_sample)\n\n\n\nmy_null_result_full <- foreach(grid = gsample, .packages = c('tidyverse', 'sf', 'cassandRa', 'vegan')) %dopar% {\n  safe_expected_values(50, all_assemblages_prunned_biog, grid, SBMs)\n  \n}\n\n\nsaveRDS(my_null_result_full, '00_Data/02_species_interactions/null-networks-grid_final_all2.RDS')\n```\n:::\n\n\n## Recuperate results\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmy_null_result_full <- readRDS('00_Data/02_species_interactions/null-networks-grid_final_all2.RDS')\nnames(my_null_result_full) <- gsample\nmres <- keep(my_null_result_full, ~ !is.null(.x$result)) \nmres <- mres |> map(~.x$result)\n\nhead(mres)\nmres_zscore <- mres \n```\n:::\n\n\n# Compute z-scores for FTA and H2\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nfta_expected_mean <- \n  mres_zscore |> \n  map(~.x['fta',] |> bind_rows() |> colMeans()) |>\n  bind_rows() |>\n  mutate(grid = names(mres_zscore))\n\n\n\nfta_expected_sd <- \n  mres_zscore |> \n  map(~.x['fta',] |> bind_rows() |> apply(2,sd)) |>\n  bind_rows() |>\n  mutate(grid = names(mres_zscore))\n\n\nfr_palm_mean <- \n  mres_zscore |> \n  map(~.x['fr_palm',] |> bind_rows() |> colMeans()) |>\n  bind_rows() |>\n  mutate(grid = names(mres_zscore))\n\nfr_mammals_mean <- \n  mres_zscore |> \n  map(~.x['fr_mammals',] |> bind_rows() |> colMeans()) |>\n  bind_rows() |>\n  mutate(grid = names(mres_zscore))\n\n\nfr_norm_palm_mean <- \n  mres_zscore |> \n  map(~.x['fr_norm_palm',] |> bind_rows() |> colMeans()) |>\n  bind_rows() |>\n  mutate(grid = names(mres_zscore))\n\nfr_norm_mammals_mean <- \n  mres_zscore |> \n  map(~.x['fr_norm_mammals',] |> bind_rows() |> colMeans()) |>\n  bind_rows() |>\n  mutate(grid = names(mres_zscore))\n\n\n\nh2_mean <- \n  mres_zscore |> \n  map(~.x['h2',]|> unlist() |> mean(na.rm = T) ) |>\n  unlist() |>\n  data.frame() |> \n  setNames('h2_x')|>\n  mutate(grid = names(mres_zscore))\n\n\nh2_sd <- \n  mres_zscore |> \n  map(~.x['h2',]|> unlist() |> sd(na.rm = T) ) |>\n  unlist() |>\n  data.frame() |> \n  setNames('h2sd')|>\n  mutate(grid = names(mres_zscore))\n\nh2_obs <- \n  mres_zscore |> \n  imap(~.x['h2',] |> unlist() |> data.frame() |> setNames('h2_obs') |>\n         mutate(grid = .y) |>\n         mutate(rep = 1:50))|>\n  bind_rows()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Define the original vector\noriginal_vector <- 1:length(mres_zscore) \n\n# Define the size of each smaller vector\nsize <- 100\n\n# Split the original vector\nsplit_vectors <- split(original_vector, gl(ceiling(length(original_vector) / size), size, length(original_vector)))\n\n\n\nfull_fta_expected <-\n  \n  split_vectors |>\n  map(function(split_vec){\n    split_vec |> \n      map(~{\n        1:50 |>\n          map(~{\n            expand.grid(\n              mres_zscore[[1]]['fr_norm_palm',.x] |> bind_rows() |> as.matrix(),\n              mres_zscore[[1]]['fr_norm_mammals',.x] |> bind_rows() |> as.matrix()\n            ) \n            \n          }) |>\n          bind_rows() |>\n          mutate(lab = bind_rows(\n            replicate(50,\n                      expand.grid(matrix(rep(1:7),ncol = 7, byrow = T),\n                                  matrix(rep(1:7),ncol = 7, byrow = T)),\n                      simplify = FALSE)) |> \n              mutate(label = paste0('p', Var1, 'm', Var2)) |> \n              dplyr::pull(label)  ) |>\n          mutate(fta = abs(Var1 - Var2)) |>\n          mutate(grid = grids_to_sample[.x]) |>\n          group_by(lab) |>\n          mutate(h2_obs = mres_zscore[[.x]]['h2',] |>unlist()) |>\n          ungroup()\n      })  |>\n      bind_rows()\n  }) |>\n  bind_rows()\n\nhead(full_fta_expected)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n## add replicate labels\nfull_fta_expected_summ <-\n  full_fta_expected |>\n  group_by(lab, grid) |>\n  summarise(fta_mean = mean(fta), \n            fta_sd = sd(fta))\n\n\nfull_fta_expected_summ$grid <- as.character(full_fta_expected_summ$grid)\n\nfull_fta_val <- \n  full_fta_expected_summ |>\n  left_join(full_fta, by = c('lab', 'grid')) \n\nhead(full_fta_val)\n\nfull_fta_val$zscore <- (full_fta_val$fta - full_fta_val$fta_mean) / full_fta_val$fta_sd\n\nsummary(full_fta_val$zscore)\n\nfull_fta_val <- \n  full_fta_val |>\n  left_join(h2_zscore, 'grid')\n\nfull_fta_val |>\n  summarize(mn = mean(fta, na.rm = T), \n            sd(fta, na.rm = T),\n            mnz = median(zscore, na.rm = T)) |>\n  arrange(desc(mnz))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nint_per_smb <- SBMs$SBM1$Omega_rs %>% \n  reshape2::melt() %>% \n  ggplot() + \n  geom_tile(aes(Var1, Var2, fill = value),  col = 'black', size = 1) + \n  theme_minimal() + \n  xlab('SBM group (mammals)') + \n  ylab('SBM group (palms)')  + \n  scale_fill_gradient(low = 'white',\n                      high = 'firebrick') + \n  theme(legend.position =\"none\") + \n  geom_text(aes(Var1, Var2, label = round(value,2))) +\n  # remove x axis labels\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()) +\n  # remove y axis labels\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) \n\n\naverage_asymmetry_heatmap <- \n  \n  full_fta_val |>\n  group_by(lab) |>\n  summarize(zscore = median(zscore, na.rm = T))  %>%\n  xtabs(zscore~lab, .) %>%\n  matrix(., nrow = 7, byrow = T) %>%\n  as.data.frame() %>%\n  # if inf change to 0\n  mutate(across(everything(), ~case_when(is.infinite(.)~ 0, TRUE ~ .))) %>% \n  as.matrix() %>% \n  reshape2::melt() %>% \n  ggplot() + \n  geom_tile(aes(Var1, Var2, fill = value),  col = 'black', size = 1) + \n  theme_minimal() + \n  xlab('SBM group (mammals)') + \n  ylab('SBM group (palms)')  + \n  scale_fill_gradient(low = 'skyblue',\n                      high = '#FF6066') + \n  theme(legend.position =\"none\") + \n  geom_text(aes(Var1, Var2, label = round(value,2))) +\n  # remove x axis labels\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()) +\n  # remove y axis labels\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) \n\n\nlibrary(gridExtra)\nlibrary(grid)\n## asemble plot with a and b labels on h\ngridExtra::grid.arrange(int_per_smb, average_asymmetry_heatmap, ncol = 2)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}